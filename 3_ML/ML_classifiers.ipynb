{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers for accident fatality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for training a Random Forest model\n",
    "\n",
    "#### First, train three basic RF models (using default settings) with the different training data (original, oversampled and undersampled)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n",
    "from joblib import load\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data with no resampling\n",
    "X_train_orig = pd.read_csv('../0_data/X_train_orig_road_acc.csv')\n",
    "y_train_orig = pd.read_csv('../0_data/y_train_orig_road_acc.csv')\n",
    "\n",
    "# Oversampled training data\n",
    "X_train_oversamp = pd.read_csv('../0_data/X_train_oversamp_road_acc.csv')\n",
    "y_train_oversamp = pd.read_csv('../0_data/y_train_oversamp_road_acc.csv')\n",
    "\n",
    "# Undersampled training data\n",
    "X_train_undersamp = pd.read_csv('../0_data/X_train_undersamp_road_acc.csv')\n",
    "y_train_undersamp = pd.read_csv('../0_data/y_train_undersamp_road_acc.csv')\n",
    "\n",
    "# Ensemble resampled training data\n",
    "X_train_ensemble = pd.read_csv('../0_data/X_train_ensemble_road_acc.csv')\n",
    "y_train_ensemble = pd.read_csv('../0_data/y_train_ensemble_road_acc.csv')\n",
    "\n",
    "\n",
    "# Validation data\n",
    "X_val = pd.read_csv('../0_data/X_val_road_acc.csv')\n",
    "y_val = pd.read_csv('../0_data/y_val_road_acc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF model trained on original (unbalanced) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF model (default values) trained on original (unbalanced) data\n",
      "Cross-validation scores for each fold: [0.98997223 0.9899275  0.98999442 0.98987172 0.99022867]\n",
      "Average cross-validation score: 0.989998906921973\n",
      "AUC Score: 0.585031640849742\n",
      "Validation Accuracy: 0.9900368542694734\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     95168\n",
      "           1       0.00      0.00      0.00       886\n",
      "\n",
      "    accuracy                           0.99     96054\n",
      "   macro avg       0.50      0.50      0.50     96054\n",
      "weighted avg       0.98      0.99      0.99     96054\n",
      "\n",
      "Confusion Matrix:\n",
      "[[95097    71]\n",
      " [  886     0]]\n"
     ]
    }
   ],
   "source": [
    "rf_clf_orig = RandomForestClassifier(random_state = 33)\n",
    "\n",
    "# 5-fold cross-validation\n",
    "cv_scores_orig = cross_val_score(rf_clf_orig, X_train_orig, y_train_orig.values.ravel(), cv = 5)\n",
    "\n",
    "# Print the cross-validation scores for each fold and the mean CV score\n",
    "print(\"RF model (default values) trained on original (unbalanced) data\")\n",
    "print(\"Cross-validation scores for each fold:\", cv_scores_orig)\n",
    "print(\"Average cross-validation score:\", cv_scores_orig.mean())\n",
    "\n",
    "# Fit the model to original training data\n",
    "rf_clf_orig.fit(X_train_orig, y_train_orig.values.ravel())\n",
    "\n",
    "# Predicting probabilities on the validation set\n",
    "prob_predictions = rf_clf_orig.predict_proba(X_val)[:, 1]  # probabilities for the positive class\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_val.values.ravel(), prob_predictions)\n",
    "print(f\"AUC Score: {auc_score}\")\n",
    "\n",
    "# Predicting class labels (for accuracy, confusion matrix, etc.)\n",
    "class_predictions = rf_clf_orig.predict(X_val)\n",
    "\n",
    "# Evaluating the model on the validation set\n",
    "val_accuracy = accuracy_score(y_val.values.ravel(), class_predictions)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_val.values.ravel(), class_predictions))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_val.values.ravel(), class_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF model trained on oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF model (default values) trained on oversampled data\n",
      "Cross-validation scores for each fold: [0.95264124 0.97006918 0.9691685  0.96983838 0.97039568]\n",
      "Average cross-validation score: 0.9664225974102694\n",
      "AUC Score: 0.5879311408523987\n",
      "Validation Accuracy: 0.9551502279967519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98     95168\n",
      "           1       0.03      0.13      0.05       886\n",
      "\n",
      "    accuracy                           0.96     96054\n",
      "   macro avg       0.51      0.55      0.51     96054\n",
      "weighted avg       0.98      0.96      0.97     96054\n",
      "\n",
      "Confusion Matrix:\n",
      "[[91630  3538]\n",
      " [  770   116]]\n"
     ]
    }
   ],
   "source": [
    "rf_clf_oversamp = RandomForestClassifier(random_state = 33)\n",
    "\n",
    "# 5-fold cross-validation\n",
    "cv_scores_oversamp = cross_val_score(rf_clf_oversamp, X_train_oversamp, y_train_oversamp.values.ravel(), cv = 5)\n",
    "\n",
    "# Print the cross-validation scores for each fold\n",
    "print(\"RF model (default values) trained on oversampled data\")\n",
    "print(\"Cross-validation scores for each fold:\", cv_scores_oversamp)\n",
    "\n",
    "# Print the average cross-validation score\n",
    "print(\"Average cross-validation score:\", cv_scores_oversamp.mean())\n",
    "\n",
    "# Fit the model to original training data\n",
    "rf_clf_oversamp.fit(X_train_oversamp, y_train_oversamp.values.ravel())\n",
    "\n",
    "# Predicting probabilities on the validation set\n",
    "prob_predictions = rf_clf_oversamp.predict_proba(X_val)[:, 1]  # probabilities for the positive class\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_val.values.ravel(), prob_predictions)\n",
    "print(f\"AUC Score: {auc_score}\")\n",
    "\n",
    "# Predicting class labels (for accuracy, confusion matrix, etc.)\n",
    "class_predictions = rf_clf_oversamp.predict(X_val)\n",
    "\n",
    "# Evaluating the model on the validation set\n",
    "val_accuracy = accuracy_score(y_val.values.ravel(), class_predictions)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_val.values.ravel(), class_predictions))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_val.values.ravel(), class_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF model trained on undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF model (default values) trained on undersampled data\n",
      "Cross-validation scores for each fold: [0.6562123  0.67410984 0.65117683 0.67229934 0.65238383]\n",
      "Average cross-validation score: 0.6612364257931224\n",
      "AUC Score: 0.6840373696756388\n",
      "Validation Accuracy: 0.6697586774106232\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.67      0.80     95168\n",
      "           1       0.02      0.62      0.03       886\n",
      "\n",
      "    accuracy                           0.67     96054\n",
      "   macro avg       0.51      0.64      0.42     96054\n",
      "weighted avg       0.99      0.67      0.79     96054\n",
      "\n",
      "Confusion Matrix:\n",
      "[[63784 31384]\n",
      " [  337   549]]\n"
     ]
    }
   ],
   "source": [
    "rf_clf_undersamp = RandomForestClassifier(random_state = 33)\n",
    "\n",
    "# 5-fold cross-validation\n",
    "cv_scores_undersamp = cross_val_score(rf_clf_undersamp, X_train_undersamp, y_train_undersamp.values.ravel(), cv = 5)\n",
    "\n",
    "# Print the cross-validation scores for each fold\n",
    "print(\"RF model (default values) trained on undersampled data\")\n",
    "print(\"Cross-validation scores for each fold:\", cv_scores_undersamp)\n",
    "\n",
    "# Print the average cross-validation score\n",
    "print(\"Average cross-validation score:\", cv_scores_undersamp.mean())\n",
    "\n",
    "# Fit the model to original training data\n",
    "rf_clf_undersamp.fit(X_train_undersamp, y_train_undersamp.values.ravel())\n",
    "\n",
    "# Predicting probabilities on the validation set\n",
    "prob_predictions = rf_clf_undersamp.predict_proba(X_val)[:, 1]  # probabilities for the positive class\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_val.values.ravel(), prob_predictions)\n",
    "print(f\"AUC Score: {auc_score}\")\n",
    "\n",
    "# Predicting class labels (for accuracy, confusion matrix, etc.)\n",
    "class_predictions = rf_clf_undersamp.predict(X_val)\n",
    "\n",
    "# Evaluating the model on the validation set\n",
    "val_accuracy = accuracy_score(y_val.values.ravel() class_predictions)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_val.values.ravel(), class_predictions))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_val.values.ravel(), class_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the models yielded particularly good results, thus some parameter tuning will be needed. We will focus on oversampled and undersampled training data only for the parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning\n",
    "\n",
    "#### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing the hyperparameter search on a subset of the whole dataset\n",
    "\n",
    "subset_size = 0.1 \n",
    "X_train_oversamp_subset = X_train_oversamp.sample(frac = subset_size, random_state = 33)\n",
    "y_train_oversamp_subset = y_train_oversamp.loc[X_train_oversamp_subset.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "# Define a parameter distribution to sample from\n",
    "param_distributions = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [None, 10, 30, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Initialize the base model\n",
    "rf_clf = RandomForestClassifier(random_state = 33)\n",
    "\n",
    "# Set up the RandomizedSearchCV object\n",
    "rf_random_search = RandomizedSearchCV(\n",
    "    estimator = rf_clf,\n",
    "    param_distributions = param_distributions,\n",
    "    n_iter = 100,\n",
    "    cv = 5, \n",
    "    verbose = 2,\n",
    "    random_state = 33,\n",
    "    n_jobs = 12\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV object to the training data\n",
    "rf_random_search.fit(X_train_oversamp_subset, y_train_oversamp_subset.values.ravel())\n",
    "\n",
    "# Get the best estimator\n",
    "best_rf_clf = rf_random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.6049742045811632\n",
      "Validation Accuracy: 0.9559726820330231\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98     95168\n",
      "           1       0.03      0.13      0.05       886\n",
      "\n",
      "    accuracy                           0.96     96054\n",
      "   macro avg       0.51      0.55      0.51     96054\n",
      "weighted avg       0.98      0.96      0.97     96054\n",
      "\n",
      "Confusion Matrix:\n",
      " [[91711  3457]\n",
      " [  772   114]]\n",
      "Best Hyperparameters:\n",
      " {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'entropy', 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "# Fit the model with the best hyperparameters on the full oversampled training data\n",
    "best_rf_clf.fit(X_train_oversamp, y_train_oversamp.values.ravel())\n",
    "\n",
    "# Predicting probabilities on the validation set for AUC calculation\n",
    "prob_predictions = best_rf_clf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_val.values.ravel(), prob_predictions)\n",
    "print(f\"AUC Score: {auc_score}\")\n",
    "\n",
    "# Predicting class labels (for accuracy, confusion matrix, etc.)\n",
    "class_predictions = best_rf_clf.predict(X_val)\n",
    "\n",
    "# Evaluating the model on the validation set\n",
    "val_accuracy = accuracy_score(y_val.values.ravel(), class_predictions)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_val.values.ravel(), class_predictions))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_val.values.ravel(), class_predictions)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\\n\", rf_random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "AUC Score: 0.736727463354338\n",
      "Validation Accuracy: 0.7450288379453224\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.85     95168\n",
      "           1       0.02      0.61      0.04       886\n",
      "\n",
      "    accuracy                           0.75     96054\n",
      "   macro avg       0.51      0.68      0.45     96054\n",
      "weighted avg       0.99      0.75      0.85     96054\n",
      "\n",
      "Confusion Matrix:\n",
      " [[71021 24147]\n",
      " [  344   542]]\n",
      "Best Hyperparameters:\n",
      " {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'entropy', 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "param_distributions = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [None, 10, 30, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Initialize the base model\n",
    "rf_clf = RandomForestClassifier(random_state = 33)\n",
    "\n",
    "# Set up the RandomizedSearchCV object\n",
    "rf_random_search = RandomizedSearchCV(\n",
    "    estimator = rf_clf,\n",
    "    param_distributions = param_distributions,\n",
    "    n_iter = 100,\n",
    "    cv = 5, \n",
    "    verbose = 2,\n",
    "    random_state = 33,\n",
    "    n_jobs = 12\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV object to the training data\n",
    "rf_random_search.fit(X_train_undersamp, y_train_undersamp.values.ravel())\n",
    "\n",
    "# Get the best estimator\n",
    "best_rf_clf = rf_random_search.best_estimator_\n",
    "\n",
    "# Fit the model with the best hyperparameters on the full oversampled training data\n",
    "best_rf_clf.fit(X_train_undersamp, y_train_undersamp.values.ravel())\n",
    "\n",
    "# Predicting probabilities on the validation set for AUC calculation\n",
    "prob_predictions = best_rf_clf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_val.values.ravel(), prob_predictions)\n",
    "print(f\"AUC Score: {auc_score}\")\n",
    "\n",
    "# Predicting class labels (for accuracy, confusion matrix, etc.)\n",
    "class_predictions = best_rf_clf.predict(X_val)\n",
    "\n",
    "# Evaluating the model on the validation set\n",
    "val_accuracy = accuracy_score(y_val.values.ravel(), class_predictions)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_val.values.ravel(), class_predictions))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_val.values.ravel(), class_predictions)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\\n\", rf_random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance of tunes models\n",
    "\n",
    "#### Oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.6049742342305247\n",
      "Validation Accuracy: 0.9559726820330231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98     95168\n",
      "           1       0.03      0.13      0.05       886\n",
      "\n",
      "    accuracy                           0.96     96054\n",
      "   macro avg       0.51      0.55      0.51     96054\n",
      "weighted avg       0.98      0.96      0.97     96054\n",
      "\n",
      "Confusion Matrix:\n",
      "[[91711  3457]\n",
      " [  772   114]]\n"
     ]
    }
   ],
   "source": [
    "# Retraining the model (in case not done at the same time as parameter tuning)\n",
    "\n",
    "best_rf_clf_over = RandomForestClassifier(n_estimators = 100,\n",
    "                                          criterion = 'entropy',\n",
    "                                          max_depth = None,\n",
    "                                          min_samples_split = 10,\n",
    "                                          min_samples_leaf = 1,\n",
    "                                          max_features = 'sqrt',\n",
    "                                          bootstrap = False,\n",
    "                                          n_jobs = 12,\n",
    "                                          random_state = 33)\n",
    "\n",
    "# Fit the model to oversampled training data\n",
    "best_rf_clf_over.fit(X_train_oversamp, y_train_oversamp.values.ravel())\n",
    "\n",
    "# Predicting probabilities on the validation set\n",
    "prob_predictions = best_rf_clf_over.predict_proba(X_val)[:, 1]  # probabilities for the positive class\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_val.values.ravel(), prob_predictions)\n",
    "print(f\"AUC Score: {auc_score}\")\n",
    "\n",
    "# Predicting class labels (for accuracy, confusion matrix, etc.)\n",
    "class_predictions = best_rf_clf_over.predict(X_val)\n",
    "\n",
    "# Evaluating the model on the validation set\n",
    "val_accuracy = accuracy_score(y_val.values.ravel(), class_predictions)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_val.values.ravel(), class_predictions))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_val.values.ravel(), class_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          feature  importance\n",
      "69                         speed_limit_bins_30-39    0.042290\n",
      "20                     junction_detail_roundabout    0.037156\n",
      "75                       time_of_day_evening_rush    0.035745\n",
      "0                              day_of_week_friday    0.034288\n",
      "6                           day_of_week_wednesday    0.033062\n",
      "..                                            ...         ...\n",
      "63  carriageway_hazards_pedestrian_in_carriageway    0.000102\n",
      "41          weather_conditions_snowing_high_winds    0.000094\n",
      "47     road_surface_conditions_oil_or_diesel_road    0.000031\n",
      "46               road_surface_conditions_mud_road    0.000008\n",
      "59                carriageway_hazards_dog_on_road    0.000007\n",
      "\n",
      "[79 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the encoder\n",
    "encoder = load('../0_data/encoder.joblib')\n",
    "\n",
    "# Get feature importances\n",
    "importances = best_rf_clf_over.feature_importances_\n",
    "\n",
    "# Get feature names\n",
    "feature_names = encoder.get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importances_df = feature_importances_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Display the feature importances\n",
    "print(feature_importances_df)\n",
    "\n",
    "feature_importances_df.to_csv('../0_data/feature_importance_RF_oversampled.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.736727463354338\n",
      "Validation Accuracy: 0.7450288379453224\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.85     95168\n",
      "           1       0.02      0.61      0.04       886\n",
      "\n",
      "    accuracy                           0.75     96054\n",
      "   macro avg       0.51      0.68      0.45     96054\n",
      "weighted avg       0.99      0.75      0.85     96054\n",
      "\n",
      "Confusion Matrix:\n",
      "[[71021 24147]\n",
      " [  344   542]]\n"
     ]
    }
   ],
   "source": [
    "# Retraining the model (in case not done at the same time as parameter tuning)\n",
    "\n",
    "best_rf_clf_under = RandomForestClassifier(n_estimators = 100,\n",
    "                                          criterion = 'entropy',\n",
    "                                          max_depth = 10,\n",
    "                                          min_samples_split = 10,\n",
    "                                          min_samples_leaf = 4,\n",
    "                                          max_features = 'log2',\n",
    "                                          bootstrap = False,\n",
    "                                          n_jobs = 12,\n",
    "                                          random_state = 33)\n",
    "\n",
    "# Fit the model to oversampled training data\n",
    "best_rf_clf_under.fit(X_train_undersamp, y_train_undersamp.values.ravel())\n",
    "\n",
    "# Predicting probabilities on the validation set\n",
    "prob_predictions = best_rf_clf_under.predict_proba(X_val)[:, 1]  # probabilities for the positive class\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_val.values.ravel(), prob_predictions)\n",
    "print(f\"AUC Score: {auc_score}\")\n",
    "\n",
    "# Predicting class labels (for accuracy, confusion matrix, etc.)\n",
    "class_predictions = best_rf_clf_under.predict(X_val)\n",
    "\n",
    "# Evaluating the model on the validation set\n",
    "val_accuracy = accuracy_score(y_val.values.ravel(), class_predictions)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_val.values.ravel(), class_predictions))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_val.values.ravel(), class_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          feature  importance\n",
      "66                      urban_or_rural_area_rural    0.102950\n",
      "20                     junction_detail_roundabout    0.102151\n",
      "69                         speed_limit_bins_30-39    0.074415\n",
      "67                      urban_or_rural_area_urban    0.069410\n",
      "72                         speed_limit_bins_60-69    0.060589\n",
      "..                                            ...         ...\n",
      "59                carriageway_hazards_dog_on_road    0.000000\n",
      "41          weather_conditions_snowing_high_winds    0.000000\n",
      "63  carriageway_hazards_pedestrian_in_carriageway    0.000000\n",
      "47     road_surface_conditions_oil_or_diesel_road    0.000000\n",
      "46               road_surface_conditions_mud_road    0.000000\n",
      "\n",
      "[79 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the encoder\n",
    "encoder = load('../0_data/encoder.joblib')\n",
    "\n",
    "# Get feature importances\n",
    "importances = best_rf_clf_under.feature_importances_\n",
    "\n",
    "# Get feature names\n",
    "feature_names = encoder.get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importances_df = feature_importances_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Display the feature importances\n",
    "print(feature_importances_df)\n",
    "\n",
    "feature_importances_df.to_csv('../0_data/feature_importance_RF_undersampled.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for training an XGBoost model\n",
    "\n",
    "#### First, train three basic XGB models (using default settings) with the different training data (original, oversampled and undersampled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from XGBoost trained on unbalanced (original) data\n",
      "Validation Accuracy: 0.990776021821059\n",
      "Validation ROC AUC Score: 0.7308531480411118\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     95168\n",
      "           1       0.00      0.00      0.00       886\n",
      "\n",
      "    accuracy                           0.99     96054\n",
      "   macro avg       0.50      0.50      0.50     96054\n",
      "weighted avg       0.98      0.99      0.99     96054\n",
      "\n",
      "Validation Confusion Matrix:\n",
      "[[95168     0]\n",
      " [  886     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\loma5202\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\loma5202\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\loma5202\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Unbalanced (original) data\n",
    "\n",
    "# Instantiate an XGBoost classifier object\n",
    "xgb_clf_orig = xgb.XGBClassifier(use_label_encoder = False, eval_metric = 'logloss', random_state = 33)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "xgb_clf_orig.fit(X_train_orig, y_train_orig.values.ravel())\n",
    "\n",
    "# Predict the labels for the validation set\n",
    "y_val_pred = xgb_clf_orig.predict(X_val)\n",
    "\n",
    "# Calculate the accuracy on the validation set\n",
    "val_accuracy = accuracy_score(y_val.values.ravel(), y_val_pred)\n",
    "\n",
    "# Calculate the ROC AUC score\n",
    "val_roc_auc = roc_auc_score(y_val.values.ravel(), xgb_clf_orig.predict_proba(X_val)[:,1])\n",
    "\n",
    "# Generate a confusion matrix\n",
    "val_conf_matrix = confusion_matrix(y_val.values.ravel(), y_val_pred)\n",
    "\n",
    "# Generate a classification report\n",
    "val_class_report = classification_report(y_val.values.ravel(), y_val_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Results from XGBoost trained on unbalanced (original) data\")\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "print(f'Validation ROC AUC Score: {val_roc_auc}')\n",
    "print('Validation Classification Report:')\n",
    "print(val_class_report)\n",
    "print('Validation Confusion Matrix:')\n",
    "print(val_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted everything as non-fatal, so using the unbalanced data here is useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from XGBoost trained on oversampled (SMOTE) data\n",
      "Validation Accuracy: 0.9583359360359798\n",
      "Validation ROC AUC Score: 0.6752880625219168\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     95168\n",
      "           1       0.04      0.15      0.06       886\n",
      "\n",
      "    accuracy                           0.96     96054\n",
      "   macro avg       0.52      0.56      0.52     96054\n",
      "weighted avg       0.98      0.96      0.97     96054\n",
      "\n",
      "Validation Confusion Matrix:\n",
      "[[91915  3253]\n",
      " [  749   137]]\n"
     ]
    }
   ],
   "source": [
    "# SMOTE oversampled data\n",
    "\n",
    "# Instantiate an XGBoost classifier object\n",
    "xgb_clf_over = xgb.XGBClassifier(use_label_encoder = False, eval_metric = 'logloss', random_state = 33)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "xgb_clf_over.fit(X_train_oversamp, y_train_oversamp.values.ravel())\n",
    "\n",
    "# Predict the labels for the validation set\n",
    "y_val_pred = xgb_clf_over.predict(X_val)\n",
    "\n",
    "# Calculate the accuracy on the validation set\n",
    "val_accuracy = accuracy_score(y_val.values.ravel(), y_val_pred)\n",
    "\n",
    "# Calculate the ROC AUC score\n",
    "val_roc_auc = roc_auc_score(y_val.values.ravel(), xgb_clf_over.predict_proba(X_val)[:,1])\n",
    "\n",
    "# Generate a confusion matrix\n",
    "val_conf_matrix = confusion_matrix(y_val.values.ravel(), y_val_pred)\n",
    "\n",
    "# Generate a classification report\n",
    "val_class_report = classification_report(y_val.values.ravel(), y_val_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Results from XGBoost trained on oversampled (SMOTE) data\")\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "print(f'Validation ROC AUC Score: {val_roc_auc}')\n",
    "print('Validation Classification Report:')\n",
    "print(val_class_report)\n",
    "print('Validation Confusion Matrix:')\n",
    "print(val_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better but still pretty bad... Only correctly predicts 137 fatal accidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from XGBoost trained on undersampled (randomised) data\n",
      "Validation Accuracy: 0.7140150332104858\n",
      "Validation ROC AUC Score: 0.7191545477471419\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.71      0.83     95168\n",
      "           1       0.02      0.63      0.04       886\n",
      "\n",
      "    accuracy                           0.71     96054\n",
      "   macro avg       0.51      0.67      0.44     96054\n",
      "weighted avg       0.99      0.71      0.82     96054\n",
      "\n",
      "Validation Confusion Matrix:\n",
      "[[68024 27144]\n",
      " [  326   560]]\n"
     ]
    }
   ],
   "source": [
    "# Randomised undersampled data\n",
    "\n",
    "# Instantiate an XGBoost classifier object\n",
    "xgb_clf_under = xgb.XGBClassifier(use_label_encoder = False, eval_metric = 'logloss', random_state = 33)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "xgb_clf_under.fit(X_train_undersamp, y_train_undersamp.values.ravel())\n",
    "\n",
    "# Predict the labels for the validation set\n",
    "y_val_pred = xgb_clf_under.predict(X_val)\n",
    "\n",
    "# Calculate the accuracy on the validation set\n",
    "val_accuracy = accuracy_score(y_val.values.ravel(), y_val_pred)\n",
    "\n",
    "# Calculate the ROC AUC score\n",
    "val_roc_auc = roc_auc_score(y_val.values.ravel(), xgb_clf_under.predict_proba(X_val)[:,1])\n",
    "\n",
    "# Generate a confusion matrix\n",
    "val_conf_matrix = confusion_matrix(y_val.values.ravel(), y_val_pred)\n",
    "\n",
    "# Generate a classification report\n",
    "val_class_report = classification_report(y_val.values.ravel(), y_val_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Results from XGBoost trained on undersampled (randomised) data\")\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "print(f'Validation ROC AUC Score: {val_roc_auc}')\n",
    "print('Validation Classification Report:')\n",
    "print(val_class_report)\n",
    "print('Validation Confusion Matrix:')\n",
    "print(val_conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even better but may be improved with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform randomised hyperparameter search to see if XGB models can be improved. Only train with over- and undersampled data.\n",
    "\n",
    "#### Oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing the hyperparameter search on a subset of the whole dataset\n",
    "\n",
    "subset_size = 0.1 \n",
    "X_train_oversamp_subset = X_train_oversamp.sample(frac = subset_size, random_state = 33)\n",
    "y_train_oversamp_subset = y_train_oversamp.loc[X_train_oversamp_subset.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best parameters found:  {'subsample': 0.7, 'n_estimators': 500, 'min_child_weight': 1, 'max_depth': 10, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
      "Validation ROC AUC Score: 0.6476119431802484\n",
      "Validation Accuracy: 0.9580444333395798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     95168\n",
      "           1       0.03      0.13      0.05       886\n",
      "\n",
      "    accuracy                           0.96     96054\n",
      "   macro avg       0.51      0.55      0.52     96054\n",
      "weighted avg       0.98      0.96      0.97     96054\n",
      "\n",
      "[[91911  3257]\n",
      " [  773   113]]\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameter grid to search\n",
    "param_grid = {\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    'subsample': [0.5, 0.7, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.7, 1.0],\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "xgb = XGBClassifier(use_label_encoder = False, eval_metric = 'logloss')\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator = xgb,\n",
    "    param_distributions = param_grid,\n",
    "    n_iter = 100,  # Number of parameter settings sampled. Adjust according to your computational resources\n",
    "    scoring = 'roc_auc',  # Can change to 'accuracy' or other metrics\n",
    "    cv = 5,\n",
    "    verbose = 2,\n",
    "    random_state = 33,\n",
    "    n_jobs = -1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV object to the training data\n",
    "random_search.fit(X_train_oversamp_subset, y_train_oversamp_subset.values.ravel())\n",
    "\n",
    "# Get the best estimator\n",
    "best_xgb_over = random_search.best_estimator_\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "\n",
    "# Train the best estimator on the full training data\n",
    "best_xgb_over.fit(X_train_oversamp, y_train_oversamp.values.ravel())\n",
    "\n",
    "# Predict probabilities on the validation set\n",
    "y_val_pred_prob = best_xgb_over.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Compute the ROC AUC score\n",
    "val_roc_auc = roc_auc_score(y_val.values.ravel(), y_val_pred_prob)\n",
    "print(f\"Validation ROC AUC Score: {val_roc_auc}\")\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_xgb_over.predict(X_val)\n",
    "\n",
    "# Compute accuracy\n",
    "val_accuracy = accuracy_score(y_val.values.ravel(), y_val_pred)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_val.values.ravel(), y_val_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_val.values.ravel(), y_val_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance of oversampled XGB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            feature  importance\n",
      "67        urban_or_rural_area_urban    0.111699\n",
      "20       junction_detail_roundabout    0.078333\n",
      "68           speed_limit_bins_20-29    0.046826\n",
      "69           speed_limit_bins_30-39    0.037532\n",
      "26  junction_control_not_a_junction    0.037153\n"
     ]
    }
   ],
   "source": [
    "# Load the encoder\n",
    "encoder = load('../0_data/encoder.joblib')\n",
    "\n",
    "# Get feature importances\n",
    "importances = best_xgb_over.feature_importances_\n",
    "\n",
    "# Get feature names\n",
    "feature_names = encoder.get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importances_df = feature_importances_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Display the feature importances\n",
    "print(feature_importances_df.head())  # Adjust the number of rows to display as needed\n",
    "\n",
    "feature_importances_df.to_csv('../0_data/feature_importance_XGB_oversampled.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best parameters found:  {'subsample': 1.0, 'n_estimators': 200, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "Validation ROC AUC Score: 0.7379815661143757\n",
      "Validation Accuracy: 0.7305786328523539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.73      0.84     95168\n",
      "           1       0.02      0.64      0.04       886\n",
      "\n",
      "    accuracy                           0.73     96054\n",
      "   macro avg       0.51      0.69      0.44     96054\n",
      "weighted avg       0.99      0.73      0.84     96054\n",
      "\n",
      "[[69606 25562]\n",
      " [  317   569]]\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameter grid to search\n",
    "param_grid = {\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    'subsample': [0.5, 0.7, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.7, 1.0],\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "xgb = XGBClassifier(use_label_encoder = False, eval_metric = 'logloss')\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator = xgb,\n",
    "    param_distributions = param_grid,\n",
    "    n_iter = 100,  # Number of parameter settings sampled. Adjust according to your computational resources\n",
    "    scoring = 'roc_auc',  # Can change to 'accuracy' or other metrics\n",
    "    cv = 5,\n",
    "    verbose = 2,\n",
    "    random_state = 33,\n",
    "    n_jobs = -1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV object to the training data\n",
    "random_search.fit(X_train_undersamp, y_train_undersamp.values.ravel())\n",
    "\n",
    "# Get the best estimator\n",
    "best_xgb_under = random_search.best_estimator_\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "\n",
    "# Train the best estimator on the full training data\n",
    "best_xgb_under.fit(X_train_undersamp, y_train_undersamp.values.ravel())\n",
    "\n",
    "# Predict probabilities on the validation set\n",
    "y_val_pred_prob = best_xgb_under.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Compute the ROC AUC score\n",
    "val_roc_auc = roc_auc_score(y_val.values.ravel(), y_val_pred_prob)\n",
    "print(f\"Validation ROC AUC Score: {val_roc_auc}\")\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_xgb_under.predict(X_val)\n",
    "\n",
    "# Compute accuracy\n",
    "val_accuracy = accuracy_score(y_val.values.ravel(), y_val_pred)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_val.values.ravel(), y_val_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_val.values.ravel(), y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model so far..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            feature  importance\n",
      "67        urban_or_rural_area_urban    0.119632\n",
      "20       junction_detail_roundabout    0.108156\n",
      "26  junction_control_not_a_junction    0.072534\n",
      "69           speed_limit_bins_30-39    0.071924\n",
      "66        urban_or_rural_area_rural    0.069595\n"
     ]
    }
   ],
   "source": [
    "# Load the encoder\n",
    "encoder = load('../0_data/encoder.joblib')\n",
    "\n",
    "# Get feature importances\n",
    "importances = best_xgb_under.feature_importances_\n",
    "\n",
    "# Get feature names\n",
    "feature_names = encoder.get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importances_df = feature_importances_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Display the feature importances\n",
    "print(feature_importances_df.head())  # Adjust the number of rows to display as needed\n",
    "\n",
    "feature_importances_df.to_csv('../0_data/feature_importance_XGB_undersampled.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best parameters found:  {'subsample': 0.7, 'n_estimators': 500, 'min_child_weight': 1, 'max_depth': 10, 'learning_rate': 0.01, 'colsample_bytree': 0.7}\n",
      "Validation ROC AUC Score: 0.7357696525929766\n",
      "Validation Accuracy: 0.8302621442105482\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.91     95168\n",
      "           1       0.03      0.51      0.05       886\n",
      "\n",
      "    accuracy                           0.83     96054\n",
      "   macro avg       0.51      0.67      0.48     96054\n",
      "weighted avg       0.99      0.83      0.90     96054\n",
      "\n",
      "[[79295 15873]\n",
      " [  431   455]]\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameter grid to search\n",
    "param_grid = {\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    'subsample': [0.5, 0.7, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.7, 1.0],\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "xgb = XGBClassifier(use_label_encoder = False, eval_metric = 'logloss')\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator = xgb,\n",
    "    param_distributions = param_grid,\n",
    "    n_iter = 100,  # Number of parameter settings sampled. Adjust according to your computational resources\n",
    "    scoring = 'roc_auc',  # Can change to 'accuracy' or other metrics\n",
    "    cv = 5,\n",
    "    verbose = 2,\n",
    "    random_state = 33,\n",
    "    n_jobs = -1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV object to the training data\n",
    "random_search.fit(X_train_ensemble, y_train_ensemble.values.ravel())\n",
    "\n",
    "# Get the best estimator\n",
    "best_xgb_ensemble = random_search.best_estimator_\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "\n",
    "# Train the best estimator on the full training data\n",
    "best_xgb_ensemble.fit(X_train_ensemble, y_train_ensemble.values.ravel())\n",
    "\n",
    "# Predict probabilities on the validation set\n",
    "y_val_pred_prob = best_xgb_ensemble.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Compute the ROC AUC score\n",
    "val_roc_auc = roc_auc_score(y_val.values.ravel(), y_val_pred_prob)\n",
    "print(f\"Validation ROC AUC Score: {val_roc_auc}\")\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = best_xgb_ensemble.predict(X_val)\n",
    "\n",
    "# Compute accuracy\n",
    "val_accuracy = accuracy_score(y_val.values.ravel(), y_val_pred)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_val.values.ravel(), y_val_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_val.values.ravel(), y_val_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
